---
title: "Le format Parquet et l'√©cosyst√®me DuckDB: l'essayer c'est l'adopter!"
subtitle: |
  **[Rencontres R 2025 - Mons]{.orange}**
author:
  - name: "[Lino Galiana](https://www.linogaliana.fr/)"
    affiliations:
        - name: "Insee"
date: 2025-05-12
date-format: short
slide-number: true
footer: |
  **Rencontres R 2025 - Mons**
lang: fr-FR
slide-tone: false
format:
  onyxia-revealjs
from: markdown+emoji
bibliography: biblio.bib
lightbox: true
---


## Pourquoi adopter le format `Parquet` ?

!["The obligatory introductory slide" [@tigani2023big]](https://motherduck.com/_next/image/?url=https%3A%2F%2Fweb-assets-prod.motherduck.com%2Fassets%2Fimg%2Fimage_2_0f68796072.jpg&w=1920&q=75){height=300 fig-align="center"}

* Un √©cosyst√®me pour r√©pondre aux besoins de volum√©trie, de performance, d'interop√©rabilit√©


## Limites du format `CSV`

- Aucune **compression** ‚Üí fichiers lourds
- Aucune **m√©tadonn√©e** : pas de types, pas de sch√©ma
- Lecture **orient√©e ligne** ‚Üí peu efficace
- Risque d'ambigu√Øt√© sur le contenu (ex : codes INSEE)

::: {.callout-warning}
**Exemple** : `01004` peut devenir `1004` si mal lu
:::

---

## Parquet : un format moderne pour les donn√©es

- **Stockage compact** :
  - Compression automatique
  - Taille r√©duite : jusqu'√† *10x plus l√©ger* qu‚Äôun CSV

- **Lecture optimis√©e** :
  - Format **orient√© colonne**
  - Ne lit que les colonnes utiles

- **Interop√©rabilit√©** :
  - Standard ouvert, lisible par R, Python, SQL, Spark...

---

## Exemple marquant

::: {.columns}
::: {.column width="60%"}

**Recensement INSEE**
- 20 millions de lignes
- 92 variables

| Format   | Taille |
|----------|--------|
| CSV      | > 4 Go |
| Parquet  | < 500 Mo |

:::

::: {.column width="40%"}
![](/slides-data/images/parquet-table1.png){fig-align="center"}
:::
:::

---

## Lecture colonne = lecture rapide

![](/slides-data/images/parquet-read-columns.png){fig-align="center" height="320"}

- Seules les colonnes n√©cessaires sont charg√©es
- Moins de m√©moire utilis√©e
- Requ√™tes analytiques plus rapides

---

## Bonus : partitionnement & tri

- Possibilit√© de **partitionner** les donn√©es (par r√©gion, ann√©e, etc.)
- Am√©liore encore les performances de lecture

![](https://ensae-reproductibilite.github.io/slides/img/partitions.png){fig-align="center" height=200}

::: {.callout-note}
Bien **choisir ses partitions** : √©viter les petits fichiers !
:::

---

## En r√©sum√©

| Avantage           | Description                            |
|--------------------|----------------------------------------|
| üì¶ Compression     | Fichiers plus l√©gers                   |
| ‚ö° Lecture rapide   | Lecture s√©lective, format en colonne   |
| üß† Sch√©ma inclus    | Typage, noms de colonnes int√©gr√©s      |
| üåê Interop√©rable    | Utilisable dans tous les langages      |
| üõ†Ô∏è Cloud-friendly   | Lecture distante possible (S3, etc.)   |

---


## Exploiter un fichier `Parquet` en R

> DuckDB : un moteur SQL en local, rapide, sans infrastructure



## Pourquoi `Parquet` ne suffit pas seul ?

- Parquet = format **de stockage**
- Il faut un moteur pour **le lire, le filtrer, l‚Äôagr√©ger**



## `DuckDB` : le moteur SQL local moderne

- Inspir√© de `SQLite`, mais **orient√© analytique**
- Con√ßu pour lire efficacement les formats colonne (`Parquet`, `Arrow`)
- Sans serveur ‚Üí ex√©cute les requ√™tes **directement en local**
- Utilisable **via SQL** ou **`dplyr`** en R



## Avantages de `DuckDB`

| üîç Fonction                  | ü¶Ü `DuckDB`                         |
|-----------------------------|-------------------------------------|
| Installation                | Une seule librairie R (`duckdb`)   |
| Lecture `Parquet`           | Native, directe, rapide             |
| Compatible S3               | Oui                                 |
| Int√©gration R (`dplyr`)     | Oui via `dbplyr`                    |
| Requ√™tes SQL                | Oui                                 |
| Lazy evaluation             | Oui                                 |



## Exemple simple avec `duckdb` en R

r
library(duckdb)
con <- dbConnect(duckdb::duckdb())

# Lire un fichier Parquet
dbGetQuery(con, "
  SELECT depcom, COUNT(*) AS n
  FROM 'data/recensement.parquet'
  WHERE dep = '01'
  GROUP BY depcom
")


- Lecture **directe** depuis le fichier
- Pas besoin d'importer en m√©moire avant d'agir



## Int√©gration avec le tidyverse

r
library(dplyr)
library(duckdb)

con <- dbConnect(duckdb())

achille <- tbl(con, "data/recensement.parquet")

achille |>
  filter(dep %in% c("01", "02")) |>
  select(depcom, idlogement) |>
  group_by(depcom) |>
  summarise(n = n()) |>
  collect()


- `tbl()` cr√©e une table **lazy**
- Les op√©rations sont **retard√©es** jusqu'√† `collect()`



## Lazy evaluation = performance ‚ö°

- Les instructions ne sont **pas ex√©cut√©es tout de suite**
- DuckDB construit un **plan d'ex√©cution optimis√©**
- Seules les donn√©es utiles sont r√©ellement lues



## Exemple : plan d'ex√©cution optimis√©

::: {.columns}
::: {.column width="50%"}
### Avant optimisation

![](/slides-data/images/lazyeval1.png){height=220}
:::

::: {.column width="50%"}
### Apr√®s optimisation

- `filter()` d√©plac√© en amont
‚Üí **Predicate pushdown**

![](/slides-data/images/lazyeval2.png){height=220}
:::
:::



## Pour aller plus loin

- Lecture directe sur **S3** :
sql
SELECT *
FROM 's3://bucket/data.parquet'
WHERE dep = '36'


- Utilisation dans un **workflow reproductible** :
  - Compatible Quarto, targets, etc.



## R√©sum√© : pourquoi `DuckDB` + `Parquet` ?

| ‚úÖ Crit√®re                     | ‚úîÔ∏è Avantage |
|------------------------------|-------------|
| Lecture fichiers massifs     | Oui         |
| Requ√™tes SQL et `dplyr`      | Oui         |
| Lazy evaluation              | Oui         |
| Sans serveur                 | Oui         |
| Cloud / S3 compatible        | Oui         |



## √Ä suivre...

> Des cas d‚Äôusage modernes : cloud, web, spatial‚Ä¶ gr√¢ce √† l‚Äô√©cosyst√®me DuckDB üß†


## Cas d‚Äôusage avanc√©s avec `DuckDB`

> Cloud, Web, Spatial ‚Äî des cas concrets pour aller plus loin



## Travailler sur des donn√©es distantes (S3)

- `DuckDB` peut lire directement depuis :
  - `s3://...`
  - `https://...`
  - Stockages cloud (compatibles S3)

- Pas besoin de :
  - Machine virtuelle
  - Cluster Spark
  - PostgreSQL distant

üí° Lecture **on-demand**, comme si le fichier √©tait local



## Exemple : lecture sur S3

sql
SELECT *
FROM 's3://insee-bucket/data/recensement.parquet'
WHERE dep = '36'


- M√™me requ√™te possible depuis R via `dbGetQuery()`
- Acc√®s simplifi√© pour les analystes



## Pourquoi c‚Äôest utile ?

| üß† Avantage                         | üí° R√©sultat                             |
|------------------------------------|-----------------------------------------|
| Acc√®s direct √† des fichiers distants | Pas besoin de les t√©l√©charger          |
| Moins de configuration              | Pas de base PostgreSQL ou VM √† g√©rer   |
| Compatible avec R, Python, SQL      | Int√©gration facile                     |
| Reproductibilit√© am√©lior√©e          | Donn√©es inchang√©es et accessibles      |



## DuckDB dans le navigateur : `duckdb-wasm` üß†

- Version WebAssembly de DuckDB
- Fonctionne dans un simple fichier `.html`
- Support√© par :
  - [`Observable`](https://observablehq.com/)
  - `Quarto` (via `ojs`)
- Id√©al pour :
  - Visualisations interactives
  - Sites statiques (sans serveur !)



## Exemple avec `duckdb-wasm` dans Quarto

js
viewof table_dvf = Inputs.table(
  duckdb.query("SELECT date, valeur_fonciere FROM dvf WHERE valeur_fonciere < 500000")
)


- ‚ö° Aucune installation c√¥t√© serveur
- Tout s‚Äôex√©cute **dans le navigateur**
- S√©curit√©, simplicit√©, performance



## Cas d‚Äôusage spatial : `GeoParquet`

- `Parquet` peut contenir des **donn√©es g√©ographiques**
  - Compatible avec la norme `GeoParquet`
  - Lecture possible via extension `SPATIAL` de DuckDB

- Permet :
  - Jointures spatiales
  - Calculs de distance
  - R√©cup√©ration des donn√©es sous forme `sf` dans R



## Exemple SQL spatial

sql
SELECT ST_Distance(a.geom, b.geom)
FROM communes a, equipements b
WHERE a.dept = '01'


- Peut √™tre ex√©cut√© dans DuckDB
- R√©sultats facilement convertibles en `sf`



## Recap des cas d‚Äôusage avanc√©s

| üöÄ Fonction              | ‚úÖ Support√© par `DuckDB`        |
|-------------------------|---------------------------------|
| Lecture sur S3 / cloud  | ‚úîÔ∏è                             |
| Ex√©cution dans le web   | ‚úîÔ∏è (via `duckdb-wasm`)         |
| Traitement spatial      | ‚úîÔ∏è (via extension `SPATIAL`)    |
| Int√©gration R/Python    | ‚úîÔ∏è (`duckdb`, `arrow`, `sf`)    |



## Un √©cosyst√®me complet

![](https://linogaliana.github.io/parquet-recensement-tutomate-slides/img/librairies2.png){fig-align="center"}

- üì¶ Stockage = `Parquet`
- üß† Traitement = `DuckDB`
- üß∞ Interface = R / SQL / Cloud / Web

‚Üí Performant, portable, reproductible



## En r√©sum√©

‚úÖ `Parquet` + `DuckDB` =
- Simplicit√©
- Performance
- Ouverture
- Reproductibilit√©
- ... et d√©sormais **Web & spatial-ready**



## Questions ? üôã

![](https://minio.lab.sspcloud.fr/lgaliana/generative-art/pythonds/kid.png){height=300}

