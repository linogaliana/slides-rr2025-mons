---
title: "Le format `Parquet` et l'√©cosyst√®me `DuckDB`: l'essayer c'est l'adopter!"
subtitle: |
  **[Rencontres R 2025 - Mons]{.orange}**
author:
  - name: "[Lino Galiana](https://www.linogaliana.fr/)"
    affiliations:
        - name: "Insee"
date: 2025-05-12
date-format: short
slide-number: true
footer: |
  **Rencontres R 2025 - Mons**
lang: fr-FR
slide-tone: false
format:
  onyxia-revealjs
from: markdown+emoji
bibliography: biblio.bib
lightbox: true
---


# Pourquoi le format `Parquet` ?

## Enjeux

- Le choix d'un format de donn√©es r√©pond √† un [**arbitrage**]{.orange} entre plusieurs crit√®res :
  - [**Public cible**]{.blue2}
  - [**Finalit√©**]{.blue2} (traitement, analyse, diffusion)
  - [**Volum√©trie**]{.blue2}
  - [**Interop√©rabilit√©**]{.blue2}

## Formats traditionnels

- Formats de donn√©es adh√©rents √† un langage ([**sas7bdat**]{.orange}, [**RDS**]{.orange}, [**fst**]{.orange}, etc.)
  - [**Non-interop√©rables**]{.blue2} -> √† √©viter !

. . .

- Le format [**CSV**]{.orange}
  - [**Interop√©rable**]{.blue2} et [**simple**]{.blue2} d'utilisation
  - Pas de gestion des [**m√©ta-donn√©es**]{.blue2}
  - Peu adapt√© aux [**donn√©es volumineuses**]{.blue2}

## Limites du `CSV` {.incremental}

:::: {.columns}

::: {.column width=70%}

- Des [**performances limit√©es**]{.orange}
  - [**Stockage**]{.blue2} : non-compress√© -> [**espace disque √©lev√©**]{.blue2}
  - [**Lecture**]{.blue2} : "orient√©-ligne" -> [**performances faibles**]{.blue2}

:::

::: {.column width=30%}


![](/slides-data/images/parquet-table1.png){fig-align="center"}

:::



- **[Pas de typage]{.orange}** des donn√©es √† l'√©criture du fichier
  - Demande expertise et pr√©caution √† la lecture
  - Exemple: <b><ins>01</ins>004</b> pour le code commune d'Amb√©rieu-en-Bugey

::::

# Les avantages du format `Parquet`

## Un format l√©ger {{< iconify fe feather color=#0f8c18 >}}

- [**Stockage**]{.orange} :
    - [**Compression**]{.blue2} : entre 5 et 20 fois plus l√©ger qu'un CSV


. . .

::: {.nonincremental}
::::: {.callout-note}
## Exemple: Recensement de la Population

- [Ficher d√©tail](https://www.insee.fr/fr/statistiques/8268848?sommaire=8205966) : 20 millions de lignes, 92 variables
    - CSV: > 4Go
    - Parquet: < 500Mo
:::::
:::

## Un format efficace

- [**Lecture**]{.orange} :
    - Jusqu‚Äô√† 34x plus rapide qu‚Äôun CSV

. . .

- [**"Orient√© colonne"**]{.orange}
  - Optimis√© pour les [**traitements analytiques**]{.blue2}
  - Limite la quantit√© de donn√©es √† mettre en m√©moire
  - Con√ßu pour √™tre √©crit une fois mais lu fr√©quemment

. . .

![](/slides-data/images/parquet-read-columns.png){fig-align="center"}


## Un format universel et fiable

- Gestion native des [**m√©ta-donn√©es**]{.orange}
  - D√©finition automatique d'un [**sch√©ma**]{.blue2} (noms, types)
  - Mise √† disposition plus [**robuste**]{.blue2}

. . .

- [**Interop√©rable**]{.orange}

. . .

- [**Open-source**]{.orange}

. . .

- Non lisible par un humain mais de plus en plus de visualiseurs en ligne


## `Parquet` : un format pl√©biscit√©

Tout un √©cosyst√®me autour de `Parquet`:

* Des formats associ√©s : `Iceberg`, `Delta`
* Des acteurs importants s'appuient dessus:

::: {.columns}
::: {.column width="30%"}
![](https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.svg)
:::
::: {.column width="30%"}
![](https://avatars.githubusercontent.com/u/120673461?s=280&v=4)
:::
::: {.column width="30%"}
![](https://randomfractalsinc.gallerycdn.vsassets.io/extensions/randomfractalsinc/duckdb-sql-tools/1.6.0/1720971368925/Microsoft.VisualStudio.Services.Icons.Default)
:::

:::

## `Parquet`: quel usage √† l'Insee ?

* __[Mise √† disposition interne]{.orange}__ de donn√©es: format privil√©gi√©

. . .

* __[Diffusion]{.orange}__: pour les donn√©es lourdes

. . .

* Permis d'utiliser {{< fa brands r-project >}} pour de la [__valorisation de donn√©es administratives__]{.orange}
    * Fin de l'h√©sitation entre `tidyverse` et `data.table`
    * Fin de la gu√©guerre {{< fa brands r-project >}} / {{< fa brands python >}}

. . .

* Socle important dans les __[[formations aux bonnes pratiques de l'Insee](https://inseefrlab.github.io/formation-bonnes-pratiques-git-R/)]{.orange}__


## La preuve !

![](https://inseefrlab.github.io/formation-bonnes-pratiques-git-R/slides/img/tableau-perf-parquet.png)


# Exploiter un fichier `Parquet`

## Enjeu

* `Parquet` ne r√©sout pas tout
  * L‚Äô[__espace disque__]{.blue2} est optimis√©
  * Les donn√©es d√©compress√©es doivent __[passer en RAM]{.blue2}__

. . .

* Le framework adapt√© d√©pend de la [__volum√©trie__]{.orange}
  * Pour la plupart des besoins : `Arrow` et `DuckDB`
  * Pour des besoins plus avanc√©s : `Spark` (de moins en moins pertinent, cf. ["_big data is dead_"](https://motherduck.com/blog/big-data-is-dead/) par Jordan Tigani)


## Les frameworks

- Deux *frameworks* de r√©f√©rence : [Arrow](https://book.utilitr.org/03_Fiches_thematiques/Fiche_arrow.html) et [DuckDB](https://book.utilitr.org/03_Fiches_thematiques/Fiche_duckdb.html)
  - Orientation [**fichier**]{.blue2} (`Arrow`) VS orientation [**BDD**]{.blue2} (`DuckDB`)

. . .

- [**Traitement en-m√©moire optimis√©**]{.orange}
  - [**Orient√©s-colonne**]{.blue2}
  - [***Lazy evaluation***]{.blue2} (prochaine slide)

. . .

- Tr√®s bonne [**int√©gration**]{.blue2}:
  - Avec le `tidyverse` ({{< fa brands r-project >}})
  - Avec le syst√®me de stockage `S3`



## Exemple simple avec `duckdb`

```r
library(duckdb)
con <- dbConnect(duckdb::duckdb())

# Lire un fichier Parquet
dbGetQuery(con, "
  FROM 'data/recensement.parquet'
  SELECT depcom, COUNT(*) AS n
  WHERE dep = '01'
  GROUP BY depcom
")
```

- Lecture **directe** du fichier, SQL _user friendly_
- Pas besoin d'importer en m√©moire avant d'agir



## Int√©gration avec le `tidyverse`

```r
library(dplyr)
library(duckdb)

con <- dbConnect(duckdb())

rp <- tbl(con, "data/recensement.parquet")

rp |>
  filter(dep == "01") |>
  select(depcom, idlogement) |>
  group_by(depcom) |>
  summarise(n = n()) |>
  collect()
```

- `tbl()` cr√©e une table **lazy**
- Les op√©rations sont **retard√©es** jusqu'√† `collect()`:
    - `DuckDB` optimise le plan pour gagner en performance


# Les opportunit√©s offertes par `DuckDB`

## Int√©gration native √† `S3`

- [__Int√©gration native avec `S3`__]{.orange}
    - Pour [**travailler sur des serveurs √† l'√©tat de l'art**]{.blue2}...
    - Plut√¥t que sur des ordinateurs aux ressources limit√©es


* On peut lire la donn√©e sur `S3` _presque comme si_ elle √©tait en local

```{.python}
FROM 's3://bucket_name/filename.extension';
SELECT *
WHERE DEPT=='36'
```

## `DuckDB` dans le navigateur


- [DuckDB WASM](https://minio.lab.sspcloud.fr/lgaliana/generative-art/ssphub/tunes_chasing.jpg) pour faire du [__`DuckDB` dans le navigateur__]{.orange} :
    - Pour des [**_dataviz_ r√©actives**]{.blue2}... dans des [**sites statiques**]{.blue2} !
    - Bye bye les gal√®res de d√©ploiement de `Shiny`, `Streamlit`...

- Simple d'usage avec `Observable` (et donc `Quarto`!)

## Exemple


```{ojs}
//| echo: false
html`
  <div style="display: flex; flex-direction: column; gap: 1rem;">

    <!-- Search bar at the top -->
    <div>${viewof search}</div>

    <!-- Two-column block -->
    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; backgroundColor: '#293845';">
      <div>${produce_histo(dvf)}</div>
      <div>${viewof table_dvf}</div>
    </div>


  </div>
`
```

```{ojs}
//| echo: false
viewof search = Inputs.select(cog, {format: x => x.LIBELLE, value: cog.find(t => t.LIBELLE == "Grasse")})

cog = db.query(`SELECT * FROM read_csv_auto("https://minio.lab.sspcloud.fr/lgaliana/data/python-ENSAE/cog_2023.csv") WHERE DEP == '06'`)
dvf = db.query(query)

db = DuckDBClient.of({})

query = `
  FROM read_parquet('https://minio.lab.sspcloud.fr/projet-formation/nouvelles-sources/data/geoparquet/dvf.parquet')
  SELECT
    CAST(date_mutation AS date) AS date,
    valeur_fonciere, code_commune,
    longitude, latitude, valeur_fonciere AS valeur_fonciere_bar
  WHERE code_commune = '${search.COM}'
`

```

```{ojs}
viewof table_dvf = Inputs.table(dvf, {columns: ["date", "valeur_fonciere"], rows: 15})

produce_histo = function(dvf){
  const histo = Plot.plot({
  style: {backgroundColor: "transparent"},
  marks: [
    Plot.rectY(dvf, Plot.binX({y: "count"}, {x: "valeur_fonciere", fill: "#ff562c"})),
    Plot.ruleY([0])
  ]
})
  return histo
}
```


## Cas d‚Äôusage spatial : `GeoParquet`

- `Parquet` peut contenir des **donn√©es g√©ographiques**
  - Compatible avec la norme `GeoParquet`
  - Lecture possible via extension `SPATIAL` de `DuckDB`

- Permet :
  - Jointures spatiales
  - Calculs de distance
  - R√©cup√©ration des donn√©es sous forme `sf` dans R




## Conclusion: `Parquet` + `DuckDB` =

- Simplicit√© et lisibilit√©

. . .

- Performance

. . .

- Interop√©rabilit√©

. . .

- Un √©cosyst√®me _cloud-ready_, _web-ready_ & _spatial-ready_



## Questions ? üôã

![](https://minio.lab.sspcloud.fr/lgaliana/generative-art/pythonds/kid.png){height=600 fig-align="center"}



# Bonus

## Partitionnement & tri

- [**Partitionner**]{.orange} ou [**ordonner**]{.orange} les donn√©es


![](https://ensae-reproductibilite.github.io/slides/img/partitions.png){fig-align="center" height="230"}

::: {.nonincremental}
::::: {.callout-warning}
## L'art de bien partitionner

- Partitionner par une/des [**variable(s) d'int√©r√™t**]{.blue2} si gros fichier
    + [**Eviter**]{.blue2} de cr√©er de [**nombreux petits (< 128Mo) fichiers**]{.blue2}
- Sinon ordonner les donn√©es avant d'√©crire le fichier (cf. [Eric Mauvi√®re](https://www.icem7.fr/outils/comment-bien-preparer-son-parquet/))

:::::
:::


## Exemple: anatomie

```{{ojs}}
viewof search = Inputs.select(cog, {format: x => x.LIBELLE, value: cog.find(t => t.LIBELLE == "Grasse")})

cog = db.query(`SELECT * FROM read_csv_auto("https://minio.lab.sspcloud.fr/lgaliana/data/python-ENSAE/cog_2023.csv") WHERE DEP == '06'`)
dvf = db.query(query)

db = DuckDBClient.of({})

query = `
  FROM read_parquet('https://minio.lab.sspcloud.fr/projet-formation/nouvelles-sources/data/geoparquet/dvf.parquet')
  SELECT
    CAST(date_mutation AS date) AS date,
    valeur_fonciere, code_commune,
    longitude, latitude, valeur_fonciere AS valeur_fonciere_bar
  WHERE code_commune = '${search.COM}'
`
```

Avec un peu de code {{< fa brands js-square >}} suppl√©mentaire ([voir sur {{< fa brands github >}}](https://github.com/linogaliana/slides-rr2025-mons))
